"""
Pass 5: Component Vocabulary

Identifies recurring UI components and captures the designer's thinking about them.
Focuses on identification, properties, and rich narratives - NOT full working code.
"""
from typing import Dict, Any, Optional, List
import json
from datetime import datetime
from .base import BasePass, PassRegistry
from app.llm import LLMService, Message, MessageRole, TextContent
from app.dtr.schemas import Pass5ComponentsDTR, ComponentInventoryItem, ComponentProperties
from app.dtr.extractors.figma_parser import parse_figma_components
from app.dtr.extractors import analyze_components_from_image


class Pass5Components(BasePass):
    """
    Pass 5: Component Vocabulary
    
    Uses Figma component extraction + vision analysis to identify components
    and generate rich narratives about the designer's component thinking.
    """
    
    def __init__(self):
        super().__init__()
        self.llm = LLMService()
    
    async def execute(
        self,
        figma_json: Optional[Dict[str, Any]] = None,
        image_bytes: Optional[bytes] = None,
        image_format: str = "png",
        prev_passes: Optional[Dict[str, Any]] = None
    ) -> Pass5ComponentsDTR:
        """
        Execute Pass 5 component extraction.
        
        Strategy:
        1. Extract components from Figma JSON (if available)
        2. Run vision analysis on image (if available)
        3. Merge results (Figma properties + vision narratives)
        4. Generate code hints from properties
        5. Synthesize global narratives
        
        Args:
            figma_json: Optional Figma JSON data
            image_bytes: Optional image data
            image_format: Image format (png, jpg, webp)
            prev_passes: Results from previous passes (Pass 2 & 3 for tokens)
        
        Returns:
            Pass5ComponentsDTR with component inventory and narratives
        """
        self._start_timing()
        
        # We need at least one input
        if figma_json is None and image_bytes is None:
            return self._create_no_components_dtr()
        
        # Scenario A: Figma JSON only
        if figma_json and not image_bytes:
            return await self._extract_from_figma(figma_json, prev_passes)
        
        # Scenario B: Image only
        if image_bytes and not figma_json:
            return await self._extract_from_vision(image_bytes, image_format, prev_passes)
        
        # Scenario C: Both (hybrid - best quality)
        return await self._extract_hybrid(figma_json, image_bytes, image_format, prev_passes)
    
    async def _extract_from_figma(
        self,
        figma_json: Dict[str, Any],
        prev_passes: Optional[Dict[str, Any]]
    ) -> Pass5ComponentsDTR:
        """Extract components from Figma JSON only."""
        print("Extracting components from Figma JSON (code-based)...")
        
        # Parse components
        figma_data = parse_figma_components(figma_json)
        
        if not figma_data.get('has_components'):
            return self._create_no_components_dtr()
        
        # Build inventory with properties from Figma
        inventory = []
        total_variants = 0
        
        for comp_data in figma_data['inventory']:
            comp_type = comp_data['type']
            variants = comp_data.get('variants', ['default'])
            properties_dict = comp_data.get('properties', {})
            
            # Convert properties dict to ComponentProperties objects
            props_objects = {}
            for variant, props in properties_dict.items():
                props_objects[variant] = ComponentProperties(**props)
            
            # Generate code hints from properties
            code_hints = {}
            for variant, props in properties_dict.items():
                code_hints[variant] = self._generate_code_hint(props)
            
            # Create inventory item with empty narratives (will be generated by LLM)
            inventory.append(ComponentInventoryItem(
                type=comp_type,
                variants=variants,
                properties=props_objects,
                code_hints=code_hints,
                narratives={},  # Will be filled by LLM
                source="figma",
                confidence=0.90
            ))
            
            total_variants += len(variants)
        
        # Generate narratives using LLM for each component
        for item in inventory:
            item.narratives = await self._generate_narratives_from_properties(
                item.type,
                item.variants,
                {v: item.properties[v].model_dump() if hasattr(item.properties[v], 'model_dump') else item.properties[v] 
                 for v in item.variants if v in item.properties}
            )
        
        # Generate global narratives
        global_narratives = await self._generate_global_narratives(
            inventory,
            authority="code"
        )
        
        elapsed = self._get_elapsed_time()
        
        return Pass5ComponentsDTR(
            authority="code",
            confidence=0.90,
            component_system_philosophy=global_narratives['system_philosophy'],
            cross_component_patterns=global_narratives['cross_patterns'],
            notable_absences=global_narratives['absences'],
            inventory=inventory_with_narratives,
            total_components=len(inventory_with_narratives),
            total_variants=total_variants
        )
    
    async def _extract_from_vision(
        self,
        image_bytes: bytes,
        image_format: str,
        prev_passes: Optional[Dict[str, Any]]
    ) -> Pass5ComponentsDTR:
        """Extract components from image only (vision analysis)."""
        print("Extracting components from image (vision-based)...")
        
        # Run vision analysis
        vision_data = await analyze_components_from_image(
            image_bytes,
            image_format,
            figma_inventory=None
        )
        
        if not vision_data.get('inventory'):
            return self._create_no_components_dtr()
        
        # Convert vision data to inventory items
        inventory = []
        for comp_data in vision_data['inventory']:
            # Convert properties to ComponentProperties objects
            props_objects = {}
            for variant, props in comp_data.get('properties', {}).items():
                props_objects[variant] = ComponentProperties(**props)
            
            inventory.append(ComponentInventoryItem(
                type=comp_data['type'],
                variants=comp_data.get('variants', ['default']),
                properties=props_objects,
                code_hints=comp_data.get('code_hints', {}),
                narratives=comp_data.get('narratives', {}),
                source="vision",
                confidence=comp_data.get('confidence', 0.75)
            ))
        
        return Pass5ComponentsDTR(
            authority="vision",
            confidence=0.75,
            component_system_philosophy=vision_data.get('component_system_philosophy', ''),
            cross_component_patterns=vision_data.get('cross_component_patterns', ''),
            notable_absences=vision_data.get('notable_absences', ''),
            inventory=inventory,
            total_components=vision_data.get('total_components', len(inventory)),
            total_variants=vision_data.get('total_variants', sum(len(c.variants) for c in inventory))
        )
    
    async def _extract_hybrid(
        self,
        figma_json: Dict[str, Any],
        image_bytes: bytes,
        image_format: str,
        prev_passes: Optional[Dict[str, Any]]
    ) -> Pass5ComponentsDTR:
        """Extract components using both Figma and vision (best quality)."""
        print("Extracting components in hybrid mode (Figma + vision)...")
        
        # 1. Parse Figma components for exact properties
        figma_data = parse_figma_components(figma_json)
        
        # 2. Run vision analysis with Figma context
        vision_data = await analyze_components_from_image(
            image_bytes,
            image_format,
            figma_inventory=figma_data.get('inventory', [])
        )
        
        # 3. Extract Pass 2 interaction states if available
        pass_2_states = {}
        if prev_passes and 'pass_2_surface' in prev_passes:
            pass_2 = prev_passes['pass_2_surface']
            if isinstance(pass_2, dict):
                colors_data = pass_2.get('colors', {})
                pass_2_states = colors_data.get('interaction_states', {})
            else:
                # Pydantic model
                pass_2_states = getattr(pass_2, 'colors', {}).get('interaction_states', {})
        
        print(f"Found {len(pass_2_states)} interaction states from Pass 2")
        
        # 4. Merge: Use union of Figma + Vision components
        inventory = []
        total_variants = 0
        
        # Build maps for both sources
        figma_by_type = {
            comp['type']: comp
            for comp in figma_data.get('inventory', [])
        }
        
        vision_by_type = {
            comp['type']: comp
            for comp in vision_data.get('inventory', [])
        }
        
        # Get union of all component types
        all_types = set(figma_by_type.keys()) | set(vision_by_type.keys())
        
        # Process each component type
        for comp_type in all_types:
            figma_comp = figma_by_type.get(comp_type)
            vision_comp = vision_by_type.get(comp_type)
            
            if figma_comp and vision_comp:
                # HYBRID: Best - use Figma properties + vision narratives
                variants = figma_comp.get('variants', ['default'])
                
                # Convert Figma properties to ComponentProperties
                props_objects = {}
                for variant, props in figma_comp.get('properties', {}).items():
                    # Apply Pass 2 interaction states if available
                    enhanced_props = self._enhance_with_pass2_states(
                        comp_type, variant, props, pass_2_states
                    )
                    props_objects[variant] = ComponentProperties(**enhanced_props)
                
                # Generate code hints from Figma properties
                code_hints = {}
                for variant, props in figma_comp.get('properties', {}).items():
                    code_hints[variant] = self._generate_code_hint(props)
                
                # Use vision narratives
                narratives = vision_comp.get('narratives', {})
                confidence = 0.95  # Highest confidence (hybrid)
                source = "hybrid"
                
            elif figma_comp:
                # FIGMA ONLY - exact but no narratives
                variants = figma_comp.get('variants', ['default'])
                
                props_objects = {}
                for variant, props in figma_comp.get('properties', {}).items():
                    enhanced_props = self._enhance_with_pass2_states(
                        comp_type, variant, props, pass_2_states
                    )
                    props_objects[variant] = ComponentProperties(**enhanced_props)
                
                code_hints = {}
                for variant, props in figma_comp.get('properties', {}).items():
                    code_hints[variant] = self._generate_code_hint(props)
                
                # Generate narratives from properties if vision missed it
                narratives = await self._generate_narratives_from_properties(comp_type, variants, props_objects)
                confidence = 0.90  # Figma exact properties
                source = "figma"
                
            else:
                # VISION ONLY - no Figma data for this component
                variants = vision_comp.get('variants', ['default'])
                
                # Convert vision properties
                props_objects = {}
                for variant, props in vision_comp.get('properties', {}).items():
                    enhanced_props = self._enhance_with_pass2_states(
                        comp_type, variant, props, pass_2_states
                    )
                    props_objects[variant] = ComponentProperties(**enhanced_props)
                
                code_hints = vision_comp.get('code_hints', {})
                narratives = vision_comp.get('narratives', {})
                confidence = 0.75  # Vision only
                source = "vision"
            
            inventory.append(ComponentInventoryItem(
                type=comp_type,
                variants=variants,
                properties=props_objects,
                code_hints=code_hints,
                narratives=narratives,
                source=source,
                confidence=confidence
            ))
            
            total_variants += len(variants)
        
        return Pass5ComponentsDTR(
            authority="hybrid",
            confidence=0.95,
            component_system_philosophy=vision_data.get('component_system_philosophy', ''),
            cross_component_patterns=vision_data.get('cross_component_patterns', ''),
            notable_absences=vision_data.get('notable_absences', ''),
            inventory=inventory,
            total_components=len(inventory),
            total_variants=total_variants
        )
    
    def _generate_code_hint(self, properties: Dict[str, Any]) -> str:
        """Generate Tailwind code hint from properties."""
        classes = []
        
        # Background
        bg = properties.get('background')
        if bg and bg != 'gradient':
            classes.append(f"bg-[{bg}]")
        
        # Text color
        text_color = properties.get('text_color')
        if text_color:
            classes.append(f"text-[{text_color}]")
        
        # Padding
        padding = properties.get('padding')
        if padding:
            # Convert "12px 24px" to "px-6 py-3" (approximate)
            parts = padding.split()
            if len(parts) == 2:
                py = int(parts[0].replace('px', '')) // 4
                px = int(parts[1].replace('px', '')) // 4
                classes.append(f"px-{px} py-{py}")
        
        # Border radius
        radius = properties.get('border_radius')
        if radius:
            px_val = int(radius.replace('px', ''))
            if px_val == 4:
                classes.append("rounded")
            elif px_val == 8:
                classes.append("rounded-lg")
            elif px_val == 12:
                classes.append("rounded-xl")
            else:
                classes.append(f"rounded-[{radius}]")
        
        # Font weight
        weight = properties.get('font_weight')
        if weight:
            if weight >= 700:
                classes.append("font-bold")
            elif weight >= 600:
                classes.append("font-semibold")
            elif weight >= 500:
                classes.append("font-medium")
        
        # Text transform
        transform = properties.get('text_transform')
        if transform == 'uppercase':
            classes.append("uppercase")
        
        # Letter spacing
        spacing = properties.get('letter_spacing')
        if spacing and spacing != 'normal':
            if 'em' in spacing:
                classes.append("tracking-wide")
            else:
                classes.append(f"tracking-[{spacing}]")
        
        # Shadow
        shadow = properties.get('shadow')
        if shadow:
            if 'shadow-lg' in classes or 'shadow-md' in classes:
                pass  # Already added
            else:
                classes.append("shadow-lg")
        
        return " ".join(classes) if classes else ""
    
    def _enhance_with_pass2_states(
        self,
        comp_type: str,
        variant: str,
        properties: Dict[str, Any],
        pass_2_states: Dict[str, str]
    ) -> Dict[str, Any]:
        """
        Enhance component properties with Pass 2 interaction states.
        
        Maps interaction states like "button-primary-hover" to component properties.
        """
        enhanced = properties.copy()
        
        # Build key patterns to look for in Pass 2 states
        # Try multiple patterns: button-primary-hover, button-hover, primary-hover
        patterns = [
            f"{comp_type}-{variant}-hover",
            f"{comp_type}-hover",
            f"{variant}-hover"
        ]
        
        for pattern in patterns:
            if pattern in pass_2_states:
                css_string = pass_2_states[pattern]
                # Parse CSS string to extract properties
                # Example: "transform: scale(1.05); box-shadow: 0px 6px 16px rgba(0,0,0,0.12); transition: all 200ms ease-out;"
                
                if 'box-shadow:' in css_string:
                    # Extract shadow
                    shadow_start = css_string.find('box-shadow:') + len('box-shadow:')
                    shadow_end = css_string.find(';', shadow_start)
                    if shadow_end > shadow_start:
                        enhanced['hover_shadow'] = css_string[shadow_start:shadow_end].strip()
                
                if 'transition:' in css_string:
                    # Extract transition
                    trans_start = css_string.find('transition:') + len('transition:')
                    trans_end = css_string.find(';', trans_start)
                    if trans_end > trans_start:
                        enhanced['transition'] = css_string[trans_start:trans_end].strip()
                
                # If we found a match, stop looking
                break
        
        # Also check for active states
        active_patterns = [
            f"{comp_type}-{variant}-active",
            f"{comp_type}-active",
            f"{variant}-active"
        ]
        
        for pattern in active_patterns:
            if pattern in pass_2_states:
                # Could extract active state properties here
                pass
        
        return enhanced
    
    async def _generate_narratives_from_properties(
        self,
        comp_type: str,
        variants: List[str],
        properties: Dict[str, Any]
    ) -> Dict[str, str]:
        """Generate rich narratives for a component from its properties using LLM."""
        print(f"Generating narratives for {comp_type}...")
        
        # Build component summary for prompt
        props_summary = []
        for variant in variants[:3]:  # Limit to first 3 variants
            if variant in properties:
                props = properties[variant]
                props_summary.append(f"{variant}: {props}")
        
        prompt = f"""Generate rich, detailed narratives for this {comp_type} component.

Component: {comp_type}
Variants: {', '.join(variants)}
Properties: {chr(10).join(props_summary)}

Generate 3-4 narratives (3-4 sentences each) explaining the designer's thinking:

1. design_thinking: WHY the designer made these visual decisions (not just WHAT exists)
2. variant_system: How variants differ and what they semantically encode
3. interaction_philosophy: How the component responds to user interaction
4. usage_patterns: Where, when, and how this component appears in the design

Return ONLY valid JSON:
{{
  "design_thinking": "3-4 sentences...",
  "variant_system": "3-4 sentences...",
  "interaction_philosophy": "3-4 sentences...",
  "usage_patterns": "3-4 sentences..."
}}"""

        try:
            response = await self.llm.generate(
                model="claude-sonnet-4-20250514",
                messages=[
                    Message(role=MessageRole.USER, content=prompt)
                ],
                max_tokens=2000,
                temperature=0.6
            )
            
            # Parse JSON response
            text = response.text.strip()
            # Remove markdown code blocks if present
            if '```json' in text:
                text = text.split('```json')[1].split('```')[0].strip()
            elif '```' in text:
                text = text.split('```')[1].split('```')[0].strip()
            
            # Find JSON object
            start = text.find('{')
            end = text.rfind('}')
            if start != -1 and end != -1:
                json_str = text[start:end+1]
                result = json.loads(json_str)
                return result
            
        except Exception as e:
            print(f"Failed to generate narratives: {e}")
        
        # Fallback
        return {
            "design_thinking": f"This {comp_type} follows clean, modern design principles.",
            "variant_system": f"Variants ({', '.join(variants)}) provide different visual weights and contexts."
        }
    
    async def _generate_global_narratives(
        self,
        inventory: List[ComponentInventoryItem],
        authority: str
    ) -> Dict[str, str]:
        """Generate global narratives about the component system."""
        print("Generating global component system narratives...")
        
        # Build summary
        comp_types = [item.type for item in inventory]
        comp_summary = f"{len(inventory)} component types: {', '.join(comp_types)}"
        
        prompt = f"""Based on these components, generate global narratives about the designer's component philosophy.

COMPONENTS: {comp_summary}

Generate 3 global narratives:
1. component_system_philosophy: Multi-paragraph synthesis of how this designer thinks about components as a system
2. cross_component_patterns: How components share visual language (radius, shadows, colors, etc.)
3. notable_absences: What's consistently absent (no pill buttons, no gradients, etc.)

Return ONLY JSON:
{{
  "system_philosophy": "Multi-paragraph text...",
  "cross_patterns": "Rich text...",
  "absences": "Rich text..."
}}"""
        
        try:
            response = await self.llm.generate(
                model="claude-sonnet-4.5",
                messages=[
                    Message(role=MessageRole.USER, content=prompt)
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            text = response.text.strip()
            if text.startswith('```'):
                lines = text.split('\n')
                text = '\n'.join(lines[1:-1])
            
            start = text.find('{')
            end = text.rfind('}')
            if start >= 0 and end >= 0:
                json_str = text[start:end+1]
                result = json.loads(json_str)
                return {
                    'system_philosophy': result.get('system_philosophy', ''),
                    'cross_patterns': result.get('cross_patterns', ''),
                    'absences': result.get('absences', '')
                }
        except Exception as e:
            print(f"Failed to generate global narratives: {e}")
        
        # Fallback
        return {
            'system_philosophy': f"Component system analysis based on {len(inventory)} identified components.",
            'cross_patterns': "Unable to analyze cross-component patterns.",
            'absences': "Unable to identify notable absences."
        }
    
    def _create_no_components_dtr(self) -> Pass5ComponentsDTR:
        """Create fallback DTR when no components found."""
        return Pass5ComponentsDTR(
            authority="none",
            confidence=0.0,
            component_system_philosophy="No components identified in this design.",
            cross_component_patterns="N/A",
            notable_absences="N/A",
            inventory=[],
            total_components=0,
            total_variants=0
        )


# Register pass
PassRegistry.register("pass_5_components", Pass5Components)


# ============================================================================
# PUBLIC API
# ============================================================================

async def run_pass_5(
    figma_json: Optional[Dict[str, Any]] = None,
    image_bytes: Optional[bytes] = None,
    image_format: str = "png",
    prev_passes: Optional[Dict[str, Any]] = None
) -> Pass5ComponentsDTR:
    """
    Run Pass 5 (Component Vocabulary).
    
    Args:
        figma_json: Optional Figma JSON
        image_bytes: Optional image data
        image_format: Image format
        prev_passes: Results from previous passes
    
    Returns:
        Pass5ComponentsDTR
    """
    pass_instance = Pass5Components()
    return await pass_instance.execute(
        figma_json=figma_json,
        image_bytes=image_bytes,
        image_format=image_format,
        prev_passes=prev_passes
    )